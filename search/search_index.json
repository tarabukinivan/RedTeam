{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#overview","title":"Overview","text":"<p>The RedTeam subnet by Innerworks is a decentralized platform designed to drive innovation in cybersecurity through competitive programming challenges. The subnet incentivizes miners to develop and submit code solutions to various technical challenges, with a focus on enhancing security. These solutions can be integrated into real-world products to improve their security features.</p>"},{"location":"#subnet-functionality","title":"Subnet Functionality","text":"<p>The subnet operates with a flexible, modular structure where new programming challenges can be added or removed based on demand. Miners submit encrypted code solutions to validators, who decrypt and evaluate the submissions after a 24-hour period. This ensures the integrity of the submissions, as the original submission time is preserved, and the solutions cannot be plagiarized. Validators run the submitted code in isolated sandbox environments to ensure accurate and replicable scoring.</p> <p>Points are awarded based on the quality of each solution, compared to the previous best. The system calculates emissions based on the number of points a miner has, with points decaying linearly over a 14-day period. This incentivizes continuous improvement and active participation in solving challenges.</p>"},{"location":"#example-challenge","title":"Example Challenge","text":"<p>For instance, a programming challenge may involve mimicking human language to bypass ai generated content detection algorithms. Miners develop Python scripts to trick the algorithm into thinking the generated content is human-written. The validators evaluate the submissions based on the accuracy of the generated content and award points accordingly. The best solution is selected as the benchmark for future submissions.</p>"},{"location":"#validator-setup","title":"Validator Setup","text":"<p>Read the full documentation</p>"},{"location":"#miner-setup","title":"Miner Setup","text":"<p>Read the full documentation</p>"},{"location":"challenge_submission_guide/","title":"Submission Guide","text":""},{"location":"challenge_submission_guide/#step-1-create-an-apppy","title":"Step 1: Create an <code>app.py</code>","text":"<p>Ensure your API server includes the following two routes:</p>"},{"location":"challenge_submission_guide/#1-health-route","title":"1. <code>/health</code> Route","text":"<ul> <li>Method: <code>GET</code></li> <li>Response: Return a JSON object with the following structure:   <pre><code>{\n    \"status\": \"ok\"\n}\n</code></pre></li> </ul>"},{"location":"challenge_submission_guide/#2-solve-route","title":"2. <code>/solve</code> Route","text":"<ul> <li>Method: <code>POST</code></li> <li>Input: Receives a <code>MinerInput</code> object. This object represents the challenge sent by the validator.</li> <li>Output: Returns a <code>MinerOutput</code> object. This object contains your response to the challenge.</li> </ul> <p>Both <code>MinerInput</code> and <code>MinerOutput</code> are defined in: <code>readteam_core/challenge_pool/&lt;challenge_name&gt;/data_types.py</code></p>"},{"location":"challenge_submission_guide/#step-2-package-your-submission-using-docker","title":"Step 2: Package Your Submission Using Docker","text":"<p>To package your submission using Docker, follow these steps:</p>"},{"location":"challenge_submission_guide/#1-create-a-requirementstxt-file","title":"1. Create a <code>requirements.txt</code> file","text":"<p>Make sure to include a <code>requirements.txt</code> file in the root directory with all necessary dependencies for your project. For example:</p> <pre><code>fastapi\nuvicorn\ntransformers\naccelerate\n</code></pre> <p>You can generate a <code>requirements.txt</code> file using <code>pip freeze &gt; requirements.txt</code> if you have a virtual environment set up.</p>"},{"location":"challenge_submission_guide/#2-create-a-dockerfile","title":"2. Create a <code>Dockerfile</code>","text":"<p>Create a <code>Dockerfile</code> in the root directory of your project to define the container image. Below is an example template for the <code>Dockerfile</code>:</p> <pre><code># Use a base image\nFROM python:3.9-slim\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the requirements file into the container\nCOPY requirements.txt .\n\n# Install the dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy all necessary files into the container\nCOPY . .\n\n# Expose the port the app runs on (must be 10002)\nEXPOSE 10002\n\n# Run the app using the command (adjust accordingly if using Flask or FastAPI)\nCMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"10002\"]\n</code></pre>"},{"location":"challenge_submission_guide/#3-build-and-test-your-docker-image","title":"3. Build and Test Your Docker Image","text":"<p>After creating the <code>Dockerfile</code> and <code>requirements.txt</code>, you can build, tag your Docker image and push it to Docker Hub. Refer to the documentation for Docker.</p> <p>You can view the tutorial for text detection submission here.</p>"},{"location":"docker/","title":"Docker Guide","text":""},{"location":"docker/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install Docker: Ensure Docker is installed and running on your system.</li> <li>Visit Docker Install Documentation for detailed instructions.</li> </ol> <p>For Ubuntu:    <code>bash    for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done    sudo apt-get update    sudo apt-get install ca-certificates curl    sudo install -m 0755 -d /etc/apt/keyrings    sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc    sudo chmod a+r /etc/apt/keyrings/docker.asc    echo \\    \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\    $(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | \\    sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null    sudo apt-get update    sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></p> <pre><code>To verify the installation, run:\n```bash\nsudo docker run hello-world\n```\n</code></pre> <ol> <li>A Docker Hub Account:</li> <li> <p>Sign up at https://hub.docker.com/ if you don\u2019t already have an account.</p> </li> <li> <p>Log in to Docker Hub:</p> </li> <li>Run the following command to log in to Docker Hub and enter your Docker Hub credentials:     <pre><code>docker login\n</code></pre></li> </ol>"},{"location":"docker/#steps-to-build-tag-and-push-a-docker-image","title":"Steps to Build, Tag, and Push a Docker Image:","text":"<ol> <li>Build the Docker Image</li> <li> <p>Navigate to the directory containing your <code>Dockerfile</code>:      <pre><code>cd /path/to/your/project\n</code></pre>      Example:      <pre><code>cd redteam_core/miner/commits/text_detection\n</code></pre></p> </li> <li> <p>Build the Docker image:      <pre><code>docker build -t &lt;image_name&gt;:&lt;tag&gt; .\n</code></pre></p> <ul> <li>Replace <code>&lt;image_name&gt;</code> with the desired name of your image (e.g., <code>challenge_name</code>).</li> <li>Replace <code>&lt;tag&gt;</code> with a version or description for the image (e.g., <code>v1.0</code>, <code>latest</code>).</li> </ul> <p>Example:  <pre><code>docker build -t challenge_name:0.0.1 .\n</code></pre></p> </li> <li> <p>Tag the Docker Image</p> </li> <li> <p>Tag your image for Docker Hub by adding your Docker Hub username:      <pre><code>docker tag &lt;image_name&gt;:&lt;tag&gt; &lt;dockerhub_username&gt;/&lt;repository_name&gt;:&lt;tag&gt;\n</code></pre></p> <ul> <li>Replace <code>&lt;dockerhub_username&gt;</code> with your Docker Hub username.</li> <li>Replace <code>&lt;repository_name&gt;</code> with the repository name you want to push to.</li> </ul> <p>Example:  <pre><code>docker tag challenge_name:0.0.1 redteam/challenge_name:0.0.1\n</code></pre></p> </li> <li> <p>Push the Docker Image to Docker Hub</p> </li> <li> <p>Push the tagged image to Docker Hub:      <pre><code>docker inspect --format='{{index .RepoDigests 0}}' &lt;dockerhub_username&gt;/&lt;repository_name&gt;:&lt;tag&gt;\n</code></pre></p> <p>Example:  <pre><code>docker inspect --format='{{index .RepoDigests 0}}' redteam/challenge_name:0.0.1\n</code></pre></p> </li> <li> <p>Retrieve the SHA256 Digest</p> </li> <li> <p>After pushing the image, retrieve the digest by running:      <pre><code>docker push &lt;dockerhub_username&gt;/&lt;repository_name&gt;:&lt;tag&gt;\n</code></pre></p> <p>Example:  <pre><code>docker push redteam/challenge_name:0.0.1\n</code></pre></p> </li> <li> <p>Verify the Image on Docker Hub</p> </li> <li>Log in to Docker Hub and navigate to your repository to ensure the image has been successfully uploaded.</li> </ol>"},{"location":"docker/#notes","title":"Notes:","text":"<ul> <li>Ensure your <code>&lt;repository_name&gt;</code> already exists on Docker Hub or create it before pushing the image.</li> <li>Use descriptive tags to manage different versions of your Docker images effectively.</li> </ul>"},{"location":"miner/","title":"Miner Setup","text":""},{"location":"miner/#minimum-system-requirements","title":"Minimum System Requirements","text":"<p>Below is the minimum system requirements for running a miner node on the RedTeam Subnet: - 8-GB RAM - 2-Cores CPU - tested on Ubuntu 22.04 But you may need more resources for engineering challenges.</p>"},{"location":"miner/#setup-instructions","title":"Setup Instructions","text":"<p>To set up a miner node on the RedTeam Subnet, follow these steps: 1. Install the latest version of the RedTeam Subnet repository. <pre><code>git clone https://github.com/RedTeamSubnet/RedTeam &amp;&amp; cd RedTeam\npip install -e .\n</code></pre></p> <ol> <li>Explore challenges at <code>redteam_core/challenge_pool/</code>, build your solution, dockerize it, and push it to Docker Hub. You can view the detailed guide here. We have some limitations on your solution:</li> <li>The solution must be a Python script.</li> <li>The solution won't be able to access the internet.</li> <li> <p>Resource limit: see Active Challenge Config</p> </li> <li> <p>Specify docker submissions for challenges at <code>neurons/miner/active_commit.yaml</code>: <pre><code>- challenge_name_1---docker_hub_id_1@&lt;sha256:digest&gt;\n- challenge_name_2---docker_hub_id_2&lt;sha256:digest&gt;\n</code></pre></p> </li> <li> <p>Start the miner node: <pre><code>pm2 start python --name \"miner_snxxx\" \\\n-- -m neurons.miner.miner \\\n--netuid xxx \\\n--wallet.name \"wallet_name\" \\\n--wallet.hotkey \"wallet_hotkey\" \\\n--axon.port \"axon_port\" \\\n--subtensor.network &lt;network&gt; \\ # default is finney\n</code></pre> Optional flags:</p> </li> <li><code>--logging.trace</code> - Enable trace logging</li> <li><code>--logging.debug</code> - Enable debug logging</li> </ol>"},{"location":"validator/","title":"Validator Setup","text":""},{"location":"validator/#minimum-system-requirements","title":"Minimum System Requirements","text":"<p>Below is the minimum system requirements for running a validator node on the RedTeam Subnet: - Bare Metal Server - GPU with 24-GB VRAM - Ubuntu 20.04 LTS - NVIDIA Driver - 32-GB RAM - 512-GB Storage - 8-Core CPU</p>"},{"location":"validator/#setup-instructions","title":"Setup Instructions","text":"<p>To set up a validator node on the RedTeam Subnet, follow these steps:</p> <ol> <li> <p>Prerequisites</p> </li> <li> <p>Install Python (&gt;= v3.10) and pip (&gt;= 23):</p> <ul> <li>[RECOMMENDED][Miniconda (v3)](https://www.anaconda.com/docs/getting-started/miniconda/install)</li> <li>[arm64/aarch64][Miniforge (v3)](https://github.com/conda-forge/miniforge)</li> <li>[Python virutal environment][venv](https://docs.python.org/3/library/venv.html)</li> </ul> </li> <li>Install graphviz</li> <li> <p>Install pygraphviz</p> </li> <li> <p>Install the latest version of the RedTeam Subnet repository. <pre><code># Clone the repository\ngit clone https://github.com/RedTeamSubnet/RedTeam &amp;&amp; cd RedTeam\n\n# Create and activate a virtual environment\npython -m venv .venv\nsource venv/bin/activate\n\n# Install the dependencies\npip install -e .\n</code></pre></p> </li> <li> <p>Install Docker Engine (guide from official Docker documentation): <pre><code>for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre></p> </li> </ol> <p>To verify the installation, run: <pre><code>sudo docker run hello-world\n</code></pre></p> <ol> <li>Install PM2 Process Manager Here is an example of how to install PM2 on Ubuntu 20.04 LTS: <pre><code># Install Node.js and npm\ncurl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n# Install PM2 globally\nsudo npm install -g pm2\n\n# Verify PM2 installation\npm2 --version\n</code></pre></li> </ol> <p>For other platforms, please refer to the PM2 Installation Guide.</p> <ol> <li> <p>Login to Hugging Face Hub Authenticate your Hugging Face Hub account. Run the following command to log in: <pre><code>huggingface-cli login\n</code></pre> You will be prompted to enter your Hugging Face access token. Visit Hugging Face Access Tokens to generate one if you don't have it already.</p> </li> <li> <p>Custom Setup for Specific Challenges For setup instructions related to specific challenges, please refer to the Validator Custom Setup.</p> </li> <li> <p>Start the validator node: <pre><code># Activate the virtual environment if not already activated\nsource venv/bin/activate\n\n# Start the validator process\npm2 start python --name \"validator_snxxx\" \\\n-- -m neurons.validator.validator \\\n--netuid xxx \\\n--wallet.name \"wallet_name\" \\\n--wallet.hotkey \"wallet_hotkey\" \\\n--subtensor.network &lt;network&gt; \\ # default is finney\n--validator.cache_dir \"./.cache/\" \\ # Your local cache dir for miners commits.\n--validator.hf_repo_id \"my_username/my_repo\" \\ # Your HF repo ID for storing miners' commits. You need to create your own repo; recommend creating a new HF account\n--validator.use_centralized_scoring \\ # Optional: Recommended for high VTRUST, opt-in to get scores of challenges from a centralized server\n</code></pre> Optional flags:</p> </li> <li><code>--logging.trace</code> - Enable trace logging</li> <li> <p><code>--logging.debug</code> - Enable debug logging</p> </li> <li> <p>(Optional but Recommended) Start the Auto-Update Script <pre><code># Activate the virtual environment if not already activated\nsource venv/bin/activate\n\n# Start auto-updater\npm2 start python --name \"validator_autoupdate\" \\\n    -- -m scripts.validator_auto_update \\\n    -- --process-name \"validator_snxxx\"\n</code></pre></p> </li> </ol>"},{"location":"validator_custom/","title":"Validator custom","text":""},{"location":"validator_custom/#custom-setup-for-specific-challenges","title":"Custom Setup for Specific Challenges","text":"<p>Some challenges include using LLM models to generate responses. We setup a vLLM server to serve the these challenges and use it in default so your validator can run the challenges without hosting one. In case you want to host your own vLLM server, you can follow the instructions below.</p> <p>To set up the environment for the Response Quality Ranker challenges and Response Quality Adversarial V2-V3 challenges, you will need to create a vLLM server.</p> <ol> <li> <p>Create a virtual environment and install the required dependencies:    <pre><code>python -m venv vllm\nsource vllm/bin/activate\npip install vllm==0.6.2\n</code></pre></p> </li> <li> <p>Run the vLLM server with the appropriate model:    <pre><code>HF_TOKEN=&lt;your-huggingface-token&gt; python -m vllm.entrypoints.openai.api_server --model unsloth/Meta-Llama-3.1-8B-Instruct --max-model-len 4096 --port &lt;your-vllm-port&gt; --gpu_memory_utilization &lt;your-gpu-memory-utilization&gt;\n</code></pre></p> </li> <li> <p>Set the necessary environment variables in Dockerfile:    <pre><code>ENV VLLM_URL=\"http://127.0.0.1:8000/v1\"  \nENV API_KEY=\"your-api-key\"\nENV VLLM_MODEL=\"unsloth/Meta-Llama-3.1-8B-Instruct\"\n</code></pre></p> </li> </ol> <p>You can find these Dockerfile in each challenge folder in the challenge_pool folders:     - redteam_core/challenge_pool/response_quality_adversarial_v2/Dockerfile     - redteam_core/challenge_pool/response_quality_adversarial_v3/Dockerfile     - redteam_core/challenge_pool/response_quality_ranker/Dockerfile     - redteam_core/challenge_pool/response_quality_ranker_v2/Dockerfile     - redteam_core/challenge_pool/response_quality_ranker_v3/Dockerfile</p>"},{"location":"diagrams/humanize_behaviour/general/","title":"Humanize behavior challenge (General)","text":"<pre><code>flowchart TD\n subgraph validator[\"Validator\"]\n        vl_forward[\"0.Forward\"]\n        vl_init_challenge[\"1.Init challenge\"]\n        vl_check_active_challenges[\"2.Check active challenges\"]\n        vl_get_miners_revealed_commits[\"3.Get miners revealed commits\"]\n        vl_use_global_scoring{\"Use global scoring?\"}\n        vl_local_scoring[\"4a.Local scoring\"]\n        vl_global_scoring[\"4b-1.Global scoring\"]\n        vl_get_centrailized_scores[\"4b-2.Get centralized scores\"]\n        vl_update_centrailized_scores[\"4b-3.Update centralized scores\"]\n        vl_create_controller[\"5.Create controller\"]\n        vl_create_comparer[\"28.Create comparer\"]\n        vl_update_miner_scores[\"34.Update miner scores\"]\n        vl_store_miner_commits[\"35.Store miner commits\"]\n        vl_store_validator_state[\"36.Store validator state\"]\n  end\n subgraph controller[\"Controller\"]\n        ct_start_challenge[\"6.Start challenge\"]\n        ct_setup_challenge[\"7./30.Setup challenge\"]\n        ct_build_challenger[\"8.Build challenger image\"]\n        ct_run_challenger[\"9.Run challenger\"]\n        ct_get_ch_tasks[\"10.Get challenger tasks\"]\n        ct_setup_miners[\"11.Setup miners\"]\n        ct_run_miners[\"12.Run miners\"]\n        ct_download_miners[\"13.Download miners\"]\n        ct_score_miners[\"14.Score miners\"]\n        ct_send_tasks_mi[\"15.Send tasks to miner\"]\n        ct_send_bot_files[\"17.Score bot files to challenger\"]\n        ct_run_refenrece_comparison[\"27.Run reference comparison to prepare compare\"]\n  end\n subgraph comparer[\"Comparer\"]\n        cm_start_comparison[\"29.Start comparison\"]\n        cm_compare_outputs[\"31.Compare outputs\"]\n  end\n subgraph cfg_manager[\"CFG manager\"]\n        cfg_run_comparison[\"33.Run CFG comparison\"]\n  end\n subgraph bot_container[\"Bot container\"]\n        bot_start_container((\"Start\"))\n        bot_run_main[\"21.Run main\"]\n        bot_run_webui_driver[\"22.Run WebUI driver\"]\n        bot_setup_driver[\"23.Setup WebUI driver\"]\n        bot_load_web_page[\"24.Load web page\"]\n        bot_run_script[\"25.Run bot script\"]\n        bot_check_tasks_done[\"26.Check tasks done\"]\n  end\n subgraph challenger_container[\"Challenger container\"]\n        ch_start_container((\"Start\"))\n        ch_server[\"Running API server\"]\n        ch_task_endpoint[\"[GET] /task\"]\n        ch_score_endpoint[\"[POST] /score\"]\n        ch_web_endpoint[\"[GET] /_web\"]\n        ch_eval_endpoint[\"[POST] /_eval\"]\n        ch_compare_endpoint[\"[POST] /compare\"]\n        ch_build_bot_image[\"18.Build bot image\"]\n        ch_run_bot_container[\"19.Run bot container\"]\n        ch_checking_scores[\"20.Keep checking scores\"]\n        ch_create_cfg_manager[\"32.Create CFG manager\"]\n        cfg_manager\n        bot_container\n  end\n subgraph miners_container[\"Miners container\"]\n        mi_start_container((\"Start\"))\n        mi_server[\"Running API server\"]\n        mi_solve_endpoint[\"[POST] /solve\"]\n        mi_read_bot_files[\"16.Read bot files\"]\n  end\n subgraph challenge[\"Challenge\"]\n        challenger_container\n        miners_container\n  end\n    start([\"Start\"]) ==&gt; validator\n    vl_forward --&gt; vl_init_challenge &amp; vl_get_miners_revealed_commits &amp; vl_store_miner_commits &amp; vl_store_validator_state\n    vl_forward ==&gt; vl_use_global_scoring\n    vl_init_challenge --&gt; vl_check_active_challenges\n    vl_use_global_scoring -- Yes --&gt; vl_global_scoring\n    vl_global_scoring --&gt; vl_get_centrailized_scores &amp; vl_update_centrailized_scores\n    vl_use_global_scoring == No ==&gt; vl_local_scoring\n    vl_local_scoring --&gt; vl_create_controller\n    vl_create_controller -.-&gt; controller\n    vl_local_scoring ==&gt; ct_start_challenge &amp; cm_start_comparison\n    vl_local_scoring --&gt; vl_create_comparer &amp; vl_update_miner_scores\n    vl_create_comparer -.-&gt; comparer\n    cm_start_comparison --&gt; ct_setup_challenge\n    cm_start_comparison ==&gt; cm_compare_outputs\n    ct_start_challenge ==&gt; ct_setup_challenge\n    ct_start_challenge --&gt; ct_get_ch_tasks\n    ct_setup_challenge --&gt; ct_build_challenger\n    ct_setup_challenge ==&gt; ct_run_challenger\n    ct_start_challenge ==&gt; ct_setup_miners &amp; ct_score_miners\n    ct_start_challenge --&gt; ct_run_refenrece_comparison\n    ct_setup_miners ==&gt; ct_run_miners\n    ct_run_miners -.-&gt; ct_download_miners\n    ct_score_miners ==&gt; ct_send_tasks_mi\n    ct_send_tasks_mi ==&gt; ct_send_bot_files\n    ct_build_challenger -. Build .-&gt; challenger_container\n    ct_run_challenger == Run ==&gt; challenger_container\n    ct_download_miners -. Download .-&gt; miners_container\n    ct_run_miners == Run ==&gt; miners_container\n    ct_get_ch_tasks &lt;-. Get tasks .-&gt; ch_task_endpoint\n    ct_send_tasks_mi &lt;== Send tasks ==&gt; mi_solve_endpoint\n    ct_send_bot_files &lt;== Score bot files ======&gt; ch_score_endpoint\n    cm_compare_outputs &lt;== Compare ==&gt; ch_compare_endpoint\n    ch_start_container --&gt; ch_server\n    ch_server o--o ch_task_endpoint &amp; ch_web_endpoint &amp; ch_eval_endpoint &amp; ch_compare_endpoint\n    ch_server o---o ch_score_endpoint\n    ch_score_endpoint --&gt; ch_build_bot_image\n    ch_score_endpoint ==&gt; ch_run_bot_container\n    ch_score_endpoint &lt;==&gt; ch_checking_scores\n    ch_checking_scores ==&gt; ch_checking_scores\n    ch_run_bot_container == Run ==&gt; bot_container\n    bot_load_web_page &lt;== Render web page ==&gt; ch_web_endpoint\n    ch_build_bot_image -. Build .-&gt; bot_container\n    bot_check_tasks_done ==&gt; ch_eval_endpoint\n    ch_eval_endpoint == Update scores ==&gt; ch_checking_scores\n    ch_compare_endpoint --&gt; ch_create_cfg_manager\n    ch_compare_endpoint ==&gt; cfg_run_comparison\n    ch_create_cfg_manager -.-&gt; cfg_manager\n    bot_start_container --&gt; bot_run_main\n    bot_run_main ==&gt; bot_run_webui_driver\n    bot_run_webui_driver ==&gt; bot_setup_driver &amp; bot_run_script &amp; bot_check_tasks_done\n    bot_setup_driver ==&gt; bot_load_web_page\n    mi_start_container --&gt; mi_server\n    mi_server o--o mi_solve_endpoint\n    mi_solve_endpoint ==&gt; mi_read_bot_files\n    vl_forward@{ shape: rect}\n    vl_init_challenge@{ shape: rect}\n    vl_check_active_challenges@{ shape: rect}\n    vl_get_miners_revealed_commits@{ shape: rect}\n    vl_local_scoring@{ shape: rect}\n    vl_global_scoring@{ shape: rect}\n    vl_get_centrailized_scores@{ shape: rect}\n    vl_update_centrailized_scores@{ shape: rect}\n    vl_create_controller@{ shape: rect}\n    vl_create_comparer@{ shape: rect}\n    vl_update_miner_scores@{ shape: rect}\n    vl_store_miner_commits@{ shape: rect}\n    vl_store_validator_state@{ shape: rect}\n    ct_start_challenge@{ shape: rect}\n    ct_setup_challenge@{ shape: rect}\n    ct_build_challenger@{ shape: rect}\n    ct_run_challenger@{ shape: rect}\n    ct_get_ch_tasks@{ shape: rect}\n    ct_setup_miners@{ shape: rect}\n    ct_run_miners@{ shape: rect}\n    ct_download_miners@{ shape: rect}\n    ct_score_miners@{ shape: rect}\n    ct_send_tasks_mi@{ shape: rect}\n    ct_send_bot_files@{ shape: rect}\n    ct_run_refenrece_comparison@{ shape: rect}\n    cm_start_comparison@{ shape: rect}\n    cm_compare_outputs@{ shape: rect}\n    cfg_run_comparison@{ shape: rect}\n    bot_run_main@{ shape: rect}\n    bot_run_webui_driver@{ shape: rect}\n    bot_setup_driver@{ shape: rect}\n    bot_load_web_page@{ shape: rect}\n    bot_run_script@{ shape: rect}\n    bot_check_tasks_done@{ shape: rect}\n    ch_server@{ shape: rect}\n    ch_task_endpoint@{ shape: rounded}\n    ch_score_endpoint@{ shape: rounded}\n    ch_web_endpoint@{ shape: rounded}\n    ch_eval_endpoint@{ shape: rounded}\n    ch_compare_endpoint@{ shape: rounded}\n    ch_build_bot_image@{ shape: rect}\n    ch_run_bot_container@{ shape: rect}\n    ch_checking_scores@{ shape: notch-pent}\n    ch_create_cfg_manager@{ shape: rect}\n    mi_server@{ shape: rect}\n    mi_solve_endpoint@{ shape: rounded}\n    mi_read_bot_files@{ shape: rect}\n</code></pre>"},{"location":"diagrams/humanize_behaviour/small/","title":"Humanize behavior challenge (Small)","text":"<pre><code>flowchart TD\n    start@{ shape: stadium, label: \"Start\" }\n    validator@{ shape: card, label: \"validator\" }\n    controller@{ shape: card, label: \"controller\" }\n\n    start --&gt; validator\n    validator -- 1.Forward --&gt; controller\n    controller -- 2.Start --&gt; challenge\n    controller -- 3.Build --&gt; challenger\n    controller -- 4.Run --&gt; challenger\n    controller -- 5.Check --&gt; ch_health_endpoint\n    controller -- 6.Download --&gt; miners\n    controller -- 7.Run --&gt; miners\n    controller -- 8.Check --&gt; mi_health_endpoint\n    controller -- 9.Get tasks --&gt; ch_task_endpoint\n    controller -- 10.Send tasks --&gt; mi_solve_endpoint\n    controller -- 11.Score bot_py --&gt; ch_score_endpoint\n    ch_score_endpoint -- 12.Build bot_py --&gt; bot_image\n    ch_score_endpoint -- 13.Run bot_py --&gt; bot_container\n    bot_container -- 14.Load web --&gt; ch_web_endpoint\n\n    subgraph challenge\n    subgraph challenger\n    bot_image@{ shape: rect, label: \"bot_image\" }\n    bot_container@{ shape: rect, label: \"bot_container\" }\n\n    ch_health_endpoint@{ shape: rounded, label: \"[GET] /health\" }\n    ch_task_endpoint@{ shape: rounded, label: \"[GET] /task\" }\n    ch_score_endpoint@{ shape: rounded, label: \"[POST] /score\" }\n    ch_web_endpoint@{ shape: rounded, label: \"[GET] /_web\" }\n    ch_compare_endpoint@{ shape: rounded, label: \"[POST] /compare\" }\n\n    end\n\n    subgraph miners\n    mi_health_endpoint@{ shape: rounded, label: \"[GET] /health\" }\n    mi_solve_endpoint@{ shape: rounded, label: \"[POST] /solve\" }\n    end\n    end</code></pre>"},{"location":"template/humanize_behaviour_v1/","title":"Humanize Behaviour v1 Submission Guide (Active after Feb 12st 2025 14:00 UTC)","text":""},{"location":"template/humanize_behaviour_v1/#description","title":"Description","text":"<p>The Humanize Behaviour v1 is designed to test the ability of a bot scripts to mimic human behaviour with a web ui form. The challenge measures how well the bot script can interact with the form and submit the required information.</p> <p>This challenge is intended to evaluate the accuracy and efficiency of bot scripts in completing web-based tasks. It assesses the ability of the bot script to navigate through the UI elements, interact with form fields, and submit the required data.</p> <p>Miners participating in this challenge should be capable of simulating human-like behaviour while interacting with the web ui form by bot script.</p>"},{"location":"template/humanize_behaviour_v1/#example-code-and-submission-instructions","title":"Example Code and Submission Instructions","text":"<p>Example code for the Humanize Behaviour v1 can be found in the <code>redteam_core/miner/commits/humanize_behaviour_v1/src/bot/bot.py</code> file.</p>"},{"location":"template/humanize_behaviour_v1/#environment","title":"Environment","text":"<p>Your bot script should be compatible with these:</p> <ul> <li>Python: 3.12</li> <li>Ubuntu: 24.04</li> <li>Docker image: selenium/standalone-chrome:4.28.1</li> </ul>"},{"location":"template/humanize_behaviour_v1/#before-you-begin","title":"Before You Begin","text":"<ul> <li>Use the template bot script provided in the <code>redteam_core/miner/commits/humanize_behaviour_v1/src/bot/bot.py</code> file.</li> <li>Inside <code>src/bot</code> folder, you will find the <code>bot.py</code> file, which contains the bot script.</li> <li>Modify only <code>run_bot()</code> function while keeping the rest of the code if you do not know what you are doing.</li> <li>The bot script must be able to:<ul> <li>Use provided <code>driver</code></li> <li>Check all click locations provided in <code>config</code> (in given order)</li> <li>Fill in username and password</li> <li>Submit the form</li> </ul> </li> <li>Do not remove or rename <code>run_bot</code> function.</li> </ul>"},{"location":"template/humanize_behaviour_v1/#things-to-remember","title":"Things to remember","text":"<ul> <li>Use provided <code>driver</code> as your main driver. If you don't follow, you may fail to run the challenge or get a low score.</li> <li>Click only in <code>provided locations</code>:<ul> <li>Clicking extra for input and submit button is ok</li> <li>If your script clicks in wrong order or skips some locations, you will not be able to submit the form</li> </ul> </li> <li>Make sure the bot scripts run on <code>headless browser</code></li> <li>Click <code>login-button</code> at the end of session; if you press it before, the session will end automatically</li> <li>Provide dependencies in <code>requirements.txt</code></li> <li>The miner docker container must be run in amd64 (x86_64) architecture because the selenium driver (chromedriver) is not compatible with arm64 architecture. If managed to run in ARM architecture, then it's up to you.</li> </ul>"},{"location":"template/humanize_behaviour_v1/#1-navigate-to-the-humanize-behaviour-v1-commit-directory","title":"1. Navigate to the Humanize Behaviour v1 Commit Directory","text":"<pre><code>cd redteam_core/miner/commits/humanize_behaviour_v1\n</code></pre>"},{"location":"template/humanize_behaviour_v1/#2-build-the-docker-image","title":"2. Build the Docker Image","text":"<p>To build the Docker image for the Humanize Behaviour v1 submission, run:</p> <pre><code>docker build -t my_hub/humanize_behaviour-miner:0.0.1 .\n\n# For MacOS (Apple Silicon) to build AMD64:\nDOCKER_BUILDKIT=1 docker build --platform linux/amd64 -t myhub/humanize_behaviour-miner:0.0.1 .\n</code></pre>"},{"location":"template/humanize_behaviour_v1/#3-log-in-to-docker","title":"3. Log in to Docker","text":"<p>Log in to your Docker Hub account using the following command:</p> <pre><code>docker login\n</code></pre> <p>Enter your Docker Hub credentials when prompted.</p>"},{"location":"template/humanize_behaviour_v1/#4-push-the-docker-image","title":"4. Push the Docker Image","text":"<p>Push the tagged image to your Docker Hub repository:</p> <pre><code>docker push myhub/humanize_behaviour:0.0.1\n</code></pre>"},{"location":"template/humanize_behaviour_v1/#5-retrieve-the-sha256-digest","title":"5. Retrieve the SHA256 Digest","text":"<p>After pushing the image, retrieve the digest by running:</p> <pre><code>docker inspect --format='{{index .RepoDigests 0}}' myhub/humanize_behaviour:0.0.1\n</code></pre>"},{"location":"template/humanize_behaviour_v1/#6-update-active_commityaml","title":"6. Update active_commit.yaml","text":"<p>Finally, go to the <code>neurons/miner/active_commit.yaml</code> file and update it with the new image tag:</p> <pre><code>- humanize_behaviour---myhub/humanize_behaviour@&lt;sha256:digest&gt;\n</code></pre>"},{"location":"template/humanize_behaviour_v1/#references","title":"\ud83d\udcd1 References","text":"<ul> <li>Docker - https://docs.docker.com</li> </ul>"},{"location":"template/humanize_behaviour_v2/","title":"Humanize Behaviour v2 Submission Guide (Active after March 18th 2025 14:00 UTC)","text":""},{"location":"template/humanize_behaviour_v2/#overview","title":"Overview","text":"<p>Humanize Behaviour v2 tests bot scripts' ability to mimic human interaction with a web UI form. It evaluates how well a bot navigates UI elements, interacts with form fields, and submits data without being caught by the bot detection system, based on  mouse movement and keyboard interaction analysis.</p> <p>Miners must demonstrate precise, human-like interactions through their bot scripts when completing the form.</p>"},{"location":"template/humanize_behaviour_v2/#example-code-and-submission-instructions","title":"Example Code and Submission Instructions","text":"<p>Example code for the Humanize Behaviour v2 can be found in the <code>redteam_core/miner/commits/humanize_behaviour_v2/src/bot/bot.py</code> file.</p>"},{"location":"template/humanize_behaviour_v2/#technical-requirements","title":"Technical Requirements","text":"<ul> <li>Python 3.12</li> <li>Ubuntu 24.04</li> <li>Docker container: selenium/standalone-chrome:4.28.1</li> </ul>"},{"location":"template/humanize_behaviour_v2/#core-requirements","title":"Core Requirements","text":"<ol> <li>Use our template from <code>redteam_core/miner/commits/humanize_behaviour_v2/src/bot/bot.py</code></li> <li>Keep the <code>run_bot()</code> function signature unchanged</li> <li>Your bot must:</li> <li>Work with the provided Selenium driver</li> <li>Follow the click sequence specified in <code>config</code></li> <li>Input text into designated fields</li> <li>Submit the form without errors</li> </ol>"},{"location":"template/humanize_behaviour_v2/#key-guidelines","title":"Key Guidelines","text":"<ul> <li>Driver Usage: Stick to the provided Selenium driver to ensure proper evaluation</li> <li>Action Sequence: Follow the provided <code>config</code> order. Clicking it at the start or in the middle will prematurely submit data and result in a zero score due to invalid action flow.</li> <li>Click Behavior:<ul> <li>Only click at specified locations</li> <li>Additional clicks for input fields and submit buttons are allowed</li> <li>Wrong click order will result in form submission failure.</li> </ul> </li> <li>Text Input:<ul> <li>Locate fields by their <code>id</code></li> <li>Use text from the <code>config</code></li> <li>Maintain the specified input order</li> </ul> </li> <li>Technical Setup:<ul> <li>Enable headless mode</li> <li>List dependencies in <code>requirements.txt</code>. See the limitations for dependencies</li> <li>Use amd64 architecture (ARM64 at your own risk)</li> <li>If your script requires system-level dependencies, add them to  <code>system_deps.txt</code>.</li> </ul> </li> <li>Limitations<ul> <li>Your script must not exceed 2,000 lines. If it does, it will be considered invalid, and you will receive a score of zero.</li> <li>Your dependencies must be older than January 1, 2025. Any package released on or after this date will not be accepted, and your script will not be processed.</li> </ul> </li> </ul>"},{"location":"template/humanize_behaviour_v2/#evaluation-criteria","title":"Evaluation Criteria","text":"<p>Your bot will be scored on these human-like behaviors:</p> <ul> <li>Mouse Movement Velocity Variation</li> <li>Mouse Movement Speed</li> <li>Mouse Movement Velocity Profiles between clicks</li> <li>Mouse Movement Granularity (average pixel per movement)</li> <li>Mouse Movement Count within the session</li> <li>Mouse Movement Trajectory Linearity</li> <li>Keypress Behavior Pattern (typing speed and variations)</li> </ul>"},{"location":"template/humanize_behaviour_v2/#plagiarism-check","title":"Plagiarism Check","text":"<p>We maintain strict originality standards:</p> <ul> <li>All submissions are compared against other miners' script</li> <li>100% similarity = zero score</li> <li>Similarity above 60% will result in proportional score penalties based on the detected similarity percentage.</li> <li>Note: Comparisons are only made against other miners\u2019 submissions, not your own previous Humanize Behaviour v2 entries.</li> </ul>"},{"location":"template/humanize_behaviour_v2/#submission-guide","title":"Submission Guide","text":"<p>Follow 1~6 steps to submit your script.</p> <ol> <li>Navigate to the Humanize Behaviour v2 Commit Directory</li> </ol> <pre><code>cd redteam_core/miner/commits/humanize_behaviour_v2\n</code></pre> <ol> <li>Build the Docker Image</li> </ol> <p>To build the Docker image for the Humanize Behaviour v2 submission, run:</p> <pre><code>docker build -t my_hub/humanize_behaviour-miner:0.0.1 .\n\n# For MacOS (Apple Silicon) to build AMD64:\nDOCKER_BUILDKIT=1 docker build --platform linux/amd64 -t myhub/humanize_behaviour-miner:0.0.1 .\n</code></pre> <ol> <li>Log in to Docker</li> </ol> <p>Log in to your Docker Hub account using the following command:</p> <pre><code>docker login\n</code></pre> <p>Enter your Docker Hub credentials when prompted.</p> <ol> <li>Push the Docker Image</li> </ol> <p>Push the tagged image to your Docker Hub repository:</p> <pre><code>docker push myhub/humanize_behaviour:0.0.1\n</code></pre> <ol> <li>Retrieve the SHA256 Digest</li> </ol> <p>After pushing the image, retrieve the digest by running:</p> <pre><code>docker inspect --format='{{index .RepoDigests 0}}' myhub/humanize_behaviour:0.0.1\n</code></pre> <ol> <li>Update active_commit.yaml</li> </ol> <p>Finally, go to the <code>neurons/miner/active_commit.yaml</code> file and update it with the new image tag:</p> <pre><code>- humanize_behaviour---myhub/humanize_behaviour@&lt;sha256:digest&gt;\n</code></pre>"},{"location":"template/humanize_behaviour_v2/#references","title":"\ud83d\udcd1 References","text":"<ul> <li>Docker - https://docs.docker.com</li> </ul>"},{"location":"template/response_quality_adversarial_v2/","title":"Response quality adversarial v2","text":""},{"location":"template/response_quality_adversarial_v2/#response-quality-adversarial-v2-submission-guide-active-after-jan-15th-2025-1400-utc","title":"Response Quality Adversarial V2 Submission Guide (Active after Jan 15th 2025 14:00 UTC)","text":""},{"location":"template/response_quality_adversarial_v2/#description","title":"Description","text":"<p>The Response Quality Adversarial V2 challenge focuses on testing miners' ability to generate responses that can trick a ranking model into misjudging their quality. Miners are provided with a modified question prompt and are tasked to generate responses that appear higher quality to the ranking model than they might actually be, based on the prompt's intent.</p> <p>This challenge is designed to encourage creativity and strategic thinking in crafting responses, pushing models to identify and exploit weaknesses in ranking systems. It simultaneously helps improve ranking models by identifying potential adversarial strategies.</p> <p>Miners should aim to develop responses that maximize their score according to the ranking model, even when the responses are not strictly aligned with the ground truth. This helps foster innovation in adversarial generation and defense techniques.</p>"},{"location":"template/response_quality_adversarial_v2/#example-code-and-submission-instructions","title":"Example Code and Submission Instructions","text":"<p>Example code for the Response Quality Adversarial Submission can be found in the <code>redteam_core/miner/commits/response_quality_adversarial</code> directory.</p> <p>Download model unsloth/Llama-3.2-3B-Instruct and place it in the <code>redteam_core/miner/commits/response_quality_adversarial</code> directory. Remember to include all model files, as miner is prevented from connecting to the internet.</p> <p>Follow the steps below to build, tag, push, and update the active commit:</p>"},{"location":"template/response_quality_adversarial_v2/#1-navigate-to-the-response-quality-adversarial-commit-directory","title":"1. Navigate to the Response Quality Adversarial Commit Directory","text":"<pre><code>cd redteam_core/miner/commits/response_quality_adversarial\n</code></pre>"},{"location":"template/response_quality_adversarial_v2/#2-build-the-docker-image","title":"2. Build the Docker Image","text":"<p>To build the Docker image for the text detection submission, run: <pre><code>docker build -t response_quality_adversarial:0.0.1 .\n</code></pre></p>"},{"location":"template/response_quality_adversarial_v2/#3-tag-the-docker-image","title":"3. Tag the Docker Image","text":"<p>After building the image, tag it with your repository name: <pre><code>docker tag response_quality_adversarial:0.0.1 myhub/response_quality_adversarial:0.0.1\n</code></pre></p>"},{"location":"template/response_quality_adversarial_v2/#4-log-in-to-docker","title":"4. Log in to Docker","text":"<p>Log in to your Docker Hub account using the following command: <pre><code>docker login\n</code></pre> Enter your Docker Hub credentials when prompted.</p>"},{"location":"template/response_quality_adversarial_v2/#5-push-the-docker-image","title":"5. Push the Docker Image","text":"<p>Push the tagged image to your Docker Hub repository: <pre><code>docker push myhub/response_quality_adversarial:0.0.1\n</code></pre></p>"},{"location":"template/response_quality_adversarial_v2/#6-retrieve-the-sha256-digest","title":"6. Retrieve the SHA256 Digest","text":"<p>After pushing the image, retrieve the digest by running: <pre><code>docker inspect --format='{{index .RepoDigests 0}}' myhub/response_quality_adversarial:0.0.1\n</code></pre></p>"},{"location":"template/response_quality_adversarial_v2/#7-update-active_commityaml","title":"7. Update active_commit.yaml","text":"<p>Finally, go to the <code>neurons/miner/active_commit.yaml</code> file and update it with the new image tag:</p> <pre><code>- response_quality_adversarial_v2---myhub/response_quality_adversarial@&lt;sha256:digest&gt;\n</code></pre>"},{"location":"template/response_quality_ranker_v2/","title":"Response Quality Ranker V2 Submission Guide (Active after Jan 15th 2025 14:00 UTC)","text":""},{"location":"template/response_quality_ranker_v2/#description","title":"Description","text":"<p>The Response Quality Ranker V2 challenge evaluates miners on their ability to rank multiple responses to a given question based on quality, including relevance, clarity, and detail. Miners must submit models capable of ranking these responses, aligning as closely as possible to the provided ground truth rankings. This challenge is designed to foster advancements in text evaluation and ranking algorithms.</p>"},{"location":"template/response_quality_ranker_v2/#example-code-and-submission-instructions","title":"Example Code and Submission Instructions","text":"<p>Example code for the Response Quality Ranker Submission can be found in the <code>redteam_core/miner/commits/response_quality_ranker</code> directory. </p> <p>Download model princeton-nlp/unsup-simcse-bert-base-uncased and place it in the <code>redteam_core/miner/commits/response_quality_ranker</code> directory. Download model snorkelai/instruction-response-quality, place it in the <code>redteam_core/miner/commits/response_quality_ranker</code> directory and rename to <code>models</code>.  Remember to include all model files, as miner is prevented from connecting to the internet.</p> <p>Follow the steps below to build, tag, push, and update the active commit:</p>"},{"location":"template/response_quality_ranker_v2/#1-navigate-to-the-response-quality-ranker-commit-directory","title":"1. Navigate to the Response Quality Ranker Commit Directory","text":"<pre><code>cd redteam_core/miner/commits/response_quality_ranker\n</code></pre>"},{"location":"template/response_quality_ranker_v2/#2-build-the-docker-image","title":"2. Build the Docker Image","text":"<p>To build the Docker image for the text detection submission, run: <pre><code>docker build -t response_quality_ranker:0.0.1 .\n</code></pre></p>"},{"location":"template/response_quality_ranker_v2/#3-tag-the-docker-image","title":"3. Tag the Docker Image","text":"<p>After building the image, tag it with your repository name: <pre><code>docker tag response_quality_ranker:0.0.1 myhub/response_quality_ranker:0.0.1\n</code></pre></p>"},{"location":"template/response_quality_ranker_v2/#4-log-in-to-docker","title":"4. Log in to Docker","text":"<p>Log in to your Docker Hub account using the following command: <pre><code>docker login\n</code></pre> Enter your Docker Hub credentials when prompted.</p>"},{"location":"template/response_quality_ranker_v2/#5-push-the-docker-image","title":"5. Push the Docker Image","text":"<p>Push the tagged image to your Docker Hub repository: <pre><code>docker push myhub/response_quality_ranker:0.0.1\n</code></pre></p>"},{"location":"template/response_quality_ranker_v2/#6-retrieve-the-sha256-digest","title":"6. Retrieve the SHA256 Digest","text":"<p>After pushing the image, retrieve the digest by running: <pre><code>docker inspect --format='{{index .RepoDigests 0}}' myhub/response_quality_ranker:0.0.1\n</code></pre></p>"},{"location":"template/response_quality_ranker_v2/#7-update-active_commityaml","title":"7. Update active_commit.yaml","text":"<p>Finally, go to the <code>neurons/miner/active_commit.yaml</code> file and update it with the new image tag:</p> <pre><code>- response_quality_ranker_v2---myhub/response_quality_ranker@&lt;sha256:digest&gt;\n</code></pre>"},{"location":"template/text_detection/","title":"Text detection","text":""},{"location":"template/text_detection/#text-detection-submission-guide-deprecated","title":"Text Detection Submission Guide (Deprecated)","text":"<p>Example code for the Text Detection Submission can be found in the <code>redteam_core/miner/commits/text_detection</code> directory. Follow the steps below to build, tag, push, and update the active commit:</p>"},{"location":"template/text_detection/#1-navigate-to-the-text-detection-commit-directory","title":"1. Navigate to the Text Detection Commit Directory","text":"<pre><code>cd redteam_core/miner/commits/text_detection\n</code></pre>"},{"location":"template/text_detection/#2-build-the-docker-image","title":"2. Build the Docker Image","text":"<p>To build the Docker image for the text detection submission, run: <pre><code>docker build -t text_detection_submission:0.0.1 .\n</code></pre></p>"},{"location":"template/text_detection/#3-tag-the-docker-image","title":"3. Tag the Docker Image","text":"<p>After building the image, tag it with your repository name: <pre><code>docker tag text_detection_submission:0.0.1 myhub/text_detection_submission:0.0.1\n</code></pre></p>"},{"location":"template/text_detection/#4-log-in-to-docker","title":"4. Log in to Docker","text":"<p>Log in to your Docker Hub account using the following command: <pre><code>docker login\n</code></pre> Enter your Docker Hub credentials when prompted.</p>"},{"location":"template/text_detection/#5-push-the-docker-image","title":"5. Push the Docker Image","text":"<p>Push the tagged image to your Docker Hub repository: <pre><code>docker push myhub/text_detection_submission:0.0.1\n</code></pre></p>"},{"location":"template/text_detection/#6-retrieve-the-sha256-digest","title":"6. Retrieve the SHA256 Digest","text":"<p>After pushing the image, retrieve the digest by running: <pre><code>docker inspect --format='{{index .RepoDigests 0}}' myhub/text_detection_submission:0.0.1\n</code></pre></p>"},{"location":"template/text_detection/#7-update-active_commityaml","title":"7. Update active_commit.yaml","text":"<p>Finally, go to the <code>neurons/miner/active_commit.yaml</code> file and update it with the new image tag:</p> <pre><code>- text_detection---myhub/text_detection_submission@&lt;sha256:digest&gt;\n</code></pre>"}]}